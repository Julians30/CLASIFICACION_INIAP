# -*- coding: utf-8 -*-
"""ML RICE.IPYNB

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uaNUK3Y1l0Ba4OSKvq9KcGZZAD4S5AMn

# ImportaciÃ³n de librerias
"""

from google.colab import files
files.upload();

# Analisis y visualizacion
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_score

# Modelos de Aprendizaje automatico multiclase
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""# ImportaciÃ³n de datos"""

df = pd.read_excel('Granos de Arroz.xlsx')
df.info()

"""# EstadÃ­sticos de resumen

**Medidas descriptivas de resumen segmentadas por cada tipo de arroz**
"""

resumen = df.groupby('Class').agg(['mean', 'std', 'median', 'quantile'])

cuartiles = df.groupby('Class').quantile([0.25, 0.75]).unstack(level=1)
cuartiles.columns = [f'{col[0]}_Q{int(col[1]*100)}' for col in cuartiles.columns]

medias = df.groupby('Class').mean().add_suffix('_media')
stds = df.groupby('Class').std().add_suffix('_std')
medianas = df.groupby('Class').median().add_suffix('_mediana')
q1 = df.groupby('Class').quantile(0.25).add_suffix('_Q1')
q3 = df.groupby('Class').quantile(0.75).add_suffix('_Q3')

resumen_final = pd.concat([medias, stds, medianas, q1, q3], axis=1)

ruta_salida = "resumen_estadistico_por_clase.xlsx"
resumen_final.to_excel(ruta_salida)

ruta_salida

"""**Tablas de distribuciÃ³n de frecuencias para los tipos de clase de arroz**"""

tabla_frecuencias = pd.DataFrame({
    'Frecuencia absoluta': df['Class'].value_counts(),
    'Frecuencia relativa (%)': df['Class'].value_counts(normalize=True) * 100
})

tabla_frecuencias = tabla_frecuencias.sort_index()

print(tabla_frecuencias)

"""**Matriz de correlaciÃ³n entre variables numÃ©ricas**"""

df_numericas = df.select_dtypes(include=['int64', 'float64'])

matriz_correlacion = df_numericas.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(matriz_correlacion, annot=True, cmap='coolwarm', fmt=".2f", square=True, cbar_kws={"shrink": 1}, annot_kws={"size": 15})
plt.xticks(fontsize=15, rotation=45, ha='right')
plt.yticks(fontsize=15, rotation=0)
plt.title('Matriz de correlaciÃ³n entre variables independientes', )
plt.tight_layout()
plt.show()

"""**AnÃ¡lisis del factor de inflacion de la varianza**"""

X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Class'], errors='ignore')

X_const = add_constant(X)

vif_data = pd.DataFrame()
vif_data['Variable'] = X_const.columns
vif_data['VIF'] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

print(vif_data)

X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Class', 'Area', 'MajorAxisLength', 'ConvexArea', 'MinorAxisLength'], errors='ignore')

X_const = add_constant(X)

vif_data = pd.DataFrame()
vif_data['Variable'] = X_const.columns
vif_data['VIF'] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

print(vif_data)

"""# TransformaciÃ³n de valores para el entrenamiento de modelos"""

le = LabelEncoder()

df['Class_codificada'] = le.fit_transform(df['Class'])

clases = dict(zip(le.classes_, le.transform(le.classes_)))
print("Mapa de clases codificadas:", clases)

"""**Entrenamiento y evaluaciÃ³n de modelos de aprendizaje**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
import pandas as pd
import numpy as np

X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Class_codificada'], errors='ignore')
y = df['Class_codificada']

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42, stratify=y
)

modelos = {
    'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'KNN': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'SVM': SVC(),
    'Naive Bayes': GaussianNB()
}

print("ðŸ“Š RESULTADOS SIN PCA:\n")
for nombre, modelo in modelos.items():
    modelo.fit(X_train, y_train)

    y_pred_train = modelo.predict(X_train)
    y_pred_test = modelo.predict(X_test)

    print(f"ðŸ”¹ Modelo: {nombre}")

    print("ðŸ”¸ Entrenamiento:")
    print(f"- Accuracy: {accuracy_score(y_train, y_pred_train):.4f}")
    print(classification_report(y_train, y_pred_train))
    print("Matriz de confusiÃ³n:\n", confusion_matrix(y_train, y_pred_train))

    print("ðŸ”¸ Prueba:")
    print(f"- Accuracy: {accuracy_score(y_test, y_pred_test):.4f}")
    print(classification_report(y_test, y_pred_test))
    print("Matriz de confusiÃ³n:\n", confusion_matrix(y_test, y_pred_test))

    print("="*60)

"""# Entrenamiendo de los modelos a traves de la metodologÃ­a de validaciÃ³n cruzada"""

print("ðŸ“Š VALIDACIÃ“N CRUZADA (5-FOLD):\n")
for nombre, modelo in modelos.items():
    scores = cross_val_score(modelo, X_scaled, y, cv=5, scoring='accuracy')
    print(f"ðŸ”¹ Modelo: {nombre}")
    print(f"- Accuracy promedio: {scores.mean():.4f}")
    print(f"- DesviaciÃ³n estÃ¡ndar: {scores.std():.4f}")
    print("="*60)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Class_codificada'], errors='ignore')
y = df['Class_codificada']

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)

mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)

y_train_pred = mlp.predict(X_train)
y_test_pred = mlp.predict(X_test)

print("ðŸ“Š RED NEURONAL SIN PCA")
print("\nðŸ”¹ Entrenamiento:")
print("Accuracy:", accuracy_score(y_train, y_train_pred))
print(classification_report(y_train, y_train_pred))
print("Matriz de ConfusiÃ³n:\n", confusion_matrix(y_train, y_train_pred))

print("\nðŸ”¹ Prueba:")
print("Accuracy:", accuracy_score(y_test, y_test_pred))
print(classification_report(y_test, y_test_pred))
print("Matriz de ConfusiÃ³n:\n", confusion_matrix(y_test, y_test_pred))

"""# ComparaciÃ³n de resultados con prueba Z"""

from statsmodels.stats.proportion import proportions_ztest
import numpy as np

# Conteos de aciertos en entrenamiento y prueba
correct_train = np.sum(y_train_pred == y_train)
correct_test  = np.sum(y_test_pred == y_test)

# TamaÃ±os muestrales
n_train = len(y_train)
n_test  = len(y_test)

# Vector de aciertos y observaciones
count = np.array([correct_train, correct_test])
nobs  = np.array([n_train, n_test])

# Prueba Z de dos proporciones (H0: p_train = p_test)
z_stat, p_value = proportions_ztest(count, nobs)

acc_train = correct_train / n_train
acc_test  = correct_test  / n_test

print("ðŸ”Ž ComparaciÃ³n de accuracy (entrenamiento vs prueba)")
print(f"Accuracy entrenamiento: {acc_train:.4f}")
print(f"Accuracy prueba       : {acc_test:.4f}")
print(f"EstadÃ­stico Z         : {z_stat:.4f}")
print(f"Valor p               : {p_value:.4g}")

if p_value < 0.05:
    print("âœ… Diferencia estadÃ­sticamente significativa (Î± = 0.05).")
else:
    print("âŒ No se encuentra diferencia estadÃ­sticamente significativa (Î± = 0.05).")

"""# ElaboraciÃ³n del grÃ¡fico de curva ROC"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier


X = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Class_codificada'], errors='ignore')
y = df['Class_codificada']


scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)


X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, stratify=y, random_state=42
)


clases = sorted(y.unique())
y_test_bin = label_binarize(y_test, classes=clases)
n_classes = y_test_bin.shape[1]


modelos = {
    'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(probability=True),
    # 'Naive Bayes': GaussianNB(),
    'Red Neuronal': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
}


plt.figure(figsize=(12, 8))

for nombre, modelo in modelos.items():
    modelo.fit(X_train, y_train)

    if hasattr(modelo, "predict_proba"):
        y_score = modelo.predict_proba(X_test)
    elif hasattr(modelo, "decision_function"):
        y_score = modelo.decision_function(X_test)
        if y_score.ndim == 1:
            y_score = np.expand_dims(y_score, axis=1)
    else:
        print(f"âš ï¸ {nombre} no soporta probabilidades.")
        continue


    if y_score.shape[1] != n_classes:
        print(f"âš ï¸ {nombre}: nÃºmero de clases en y_score incorrecto ({y_score.shape[1]} vs {n_classes}). Se omite.")
        continue


    fpr, tpr = dict(), dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])


    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
    mean_tpr = np.zeros_like(all_fpr)
    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
    mean_tpr /= n_classes

    roc_auc = auc(all_fpr, mean_tpr)
    plt.plot(all_fpr, mean_tpr, label=f"{nombre} (AUC = {roc_auc:.2f})")


plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlabel("Tasa de Falsos Positivos (FPR)", fontsize=20)
plt.ylabel("Tasa de Verdaderos Positivos (TPR)", fontsize=20)
plt.title("Curvas ROC (Promedio Macro) - ClasificaciÃ³n Multiclase",fontsize=20)
plt.legend(loc="lower right", fontsize=20)
plt.grid(True)
plt.tight_layout()
plt.show()

# â–¶ï¸ 7. GrÃ¡fico final
plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlabel("Tasa de Falsos Positivos (FPR)")
plt.ylabel("Tasa de Verdaderos Positivos (TPR)")
plt.title("Curvas ROC (Promedio Macro) - ClasificaciÃ³n Multiclase",fontsize=15)
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

"""# ReducciÃ³n de dimensionalidad a traves de AnÃ¡lisis de Componentes Principales (ACP)"""

features = df.drop("Class").columns

X = df[features].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA()
X_pca = pca.fit_transform(X_scaled)

explained = pca.explained_variance_ratio_
cumexp = explained.cumsum()

print("Varianza explicada por componente:")
for i, v in enumerate(explained, 1):
    print(f"PC{i}: {v:.4f}")

print("\nVarianza explicada acumulada:")
for i, v in enumerate(cumexp, 1):
    print(f"PC1â€“PC{i}: {v:.4f}")

# Scree plot y acumulada
plt.figure(figsize=(7,4))
plt.plot(range(1, len(features)+1), explained, marker='o')
plt.title("Scree plot (varianza explicada por PC)")
plt.xlabel("Componente principal")
plt.ylabel("Varianza explicada")
plt.grid(True)
plt.show()

plt.figure(figsize=(7,4))
plt.plot(range(1, len(features)+1), cumexp, marker='o')
plt.title("Varianza explicada acumulada")
plt.xlabel("NÃºmero de componentes")
plt.ylabel("Varianza explicada acumulada")
plt.grid(True)
plt.show()

# DataFrame con PCs y nÃºmero de componentes para â‰¥90% de varianza
df_pca = pd.DataFrame(X_pca, columns=[f"PC{i}" for i in range(1, len(features)+1)])
df_pca["target"] = df["variedad"]

umbral = 0.90
n_opt = int(np.searchsorted(cumexp, umbral) + 1)
print(f"\nNÃºmero de componentes para â‰¥{int(umbral*100)}% de varianza: {n_opt}")
X_pca_reducido = X_pca[:, :n_opt]